import os
import io
import base64
from tqdm import tqdm
from fastapi import APIRouter, HTTPException
import pandas as pd
import logging
from .model import setup_llm_pipeline
from .utils import load_file
from transformers import pipeline
import matplotlib.pyplot as plt
import numpy as np

# langchain ëª¨ë“ˆ
from langchain_core.callbacks.base import BaseCallbackHandler
from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_community.document_loaders import CSVLoader, UnstructuredExcelLoader, PDFPlumberLoader, DataFrameLoader, Docx2txtLoader, TextLoader, JSONLoader
from langchain_teddynote.document_loaders import HWPLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.runnables import RunnablePassthrough, RunnableParallel
from langchain.schema import StrOutputParser

# íŒŒì¸íŠœë‹ 
from langchain_community.vectorstores import Chroma, FAISS
from langchain_community.vectorstores.utils import DistanceStrategy
from langchain_community.retrievers import BM25Retriever 
from langchain_teddynote.retrievers import KiwiBM25Retriever
from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever
from langchain.retrievers.document_compressors import CrossEncoderReranker
from langchain_community.cross_encoders import HuggingFaceCrossEncoder
from langchain_community.document_transformers import LongContextReorder
from sentence_transformers import CrossEncoder

# ì—ì´ì „íŠ¸
from langchain.tools.retriever import create_retriever_tool
from langchain.agents import create_react_agent, create_json_chat_agent
from langchain.agents import AgentExecutor
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

# ë³‘ë ¬ì²˜ë¦¬ (í•™ìŠµì†ë„ ê°€ì†)
from concurrent.futures import ProcessPoolExecutor
import multiprocessing

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)

router = APIRouter(prefix="/gangjin") # APIRouter ë³€í™˜

upload_files = {}
model_name = "llama3.2-bllossom" 


# llm = setup_llm_pipeline()

llm = ChatOllama(model=model_name) 
print(f"ì‚¬ìš©ë˜ëŠ” ëª¨ë¸: {llm}")  # ëª¨ë¸ ì´ë¦„ ì¶œë ¥

@router.get("/response_llama_data",  tags=["CHAT BOT API SERVER"]) 
def response_llama_data(prompt : str):
    # ëª¨ë¸ì— ë©”ì‹œì§€ ì „ë‹¬
    try:
        # System Prompt ì ìš© (ìœ„ì—ì„œ ì„¤ê³„í•œ ë²„ì „)
        system_prompt = """ë‹¹ì‹ ì€ ê°•ì§„ì—ì„œ ì œê³µí•˜ëŠ” ì±—ë´‡ ì•ˆë‚´ì›ìœ¼ë¡œ, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ê³µì†í•˜ê²Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. 
                íŒŒì¼ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ë°ì´í„°ë¥¼ ì •í™•íˆ ì½ê³  í•„ìš”í•œ ì •ë³´ë¥¼ ê°„ëµí•˜ê²Œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

                ### ğŸ”¹ **ğŸ“Œ í•µì‹¬ ì›ì¹™**
                1. **ë‹µë³€ ì‹œ ìœ ì˜ ì‚¬í•­**: 
                    - ì…ë ¥ë°›ì€ ë°ì´í„° ë‚´ì— ìˆëŠ” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì´ ì§ˆë¬¸í•˜ëŠ” ì •ë³´ì˜ ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
                    - ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•  ì‹œ í•´ë‹¹ ì •ë³´ë¥¼ ë‹¤ì‹œ ë¬¼ì–´ë´ì•¼ í•©ë‹ˆë‹¤.
            
                2. **ì–¸ì–´ ì •ì±…**:
                    - ê¸°ë³¸ì ìœ¼ë¡œ **ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´**ë¡œ ì‘ì„±ë©ë‹ˆë‹¤.
                    - ì§ˆë¬¸ì— **í•œêµ­ì–´ê°€ í¬í•¨ëœ ê²½ìš°** ìµœëŒ€í•œ í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
                    - ì§ˆë¬¸ì´ **í•œêµ­ì–´ê°€ ì•„ë‹Œ ê²½ìš°**, í•´ë‹¹ ì–¸ì–´ë¡œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                
                3. **ë‹µë³€ ìŠ¤íƒ€ì¼**:
                    - ë‹µë³€ì˜ ëì—ëŠ” ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆë„ë¡ **ì¹œì ˆí•œ ì•ˆë‚´ ë¬¸êµ¬**ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
                    - **ì¤‘ë³µì„ í”¼í•˜ê³ , í•µì‹¬ ì •ë³´ë§Œ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ì œê³µ**í•©ë‹ˆë‹¤.
                """

        # Ollamaì—ì„œ ìš”êµ¬í•˜ëŠ” ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ]
        response = llm.invoke(messages)
        
        # âœ… AIMessage ê°ì²´ì—ì„œ content(ë¬¸ìì—´) ê°’ë§Œ ê°€ì ¸ì˜¤ê¸°
        answer_text = response.content if hasattr(response, 'content') else str(response)
        print(type(answer_text), answer_text[:500])
        
        # ì´ì œ response_data["answer"]ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        return {"message": answer_text[:500]}
    
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        
# ========================================================================= # 
# ì…ë ¥ëœ ë°ì´í„° ìˆì„ ì‹œ í•´ë‹¹ ë°ì´í„° ì½ê³  í•™ìŠµí•˜ëŠ” ì½”ë“œ     
@router.get("/response_read_data",  tags=["CHAT BOT API SERVER"]) 
def response_read_data(message: str, file_path: str, filename: str, min_chunk_size : int = 50):
    """ë°ì´í„° íŒŒì¼ì„ ì½ê³ , ë²¡í„°í™”í•˜ëŠ” í•¨ìˆ˜"""
    # ëª¨ë¸ ì´ˆê¸°í™”
    try:
        # íŒŒì¼ ê²½ë¡œì™€ ì´ë¦„
        target_path = file_path
        file_type = filename.split('.')[-1].lower()
        
        # file_type = filename.split('.')[-1].lower()
        # target_path = f'./templates/{file_path}/{filename}'
        
        # í•¨ìˆ˜í™” ì¤‘
        # load_file(file_path, filename)
        
        # ìë£Œí˜•ë³„ë¡œ íŒŒì¼ ë¡œë“œ
        if file_type == "pdf":
            loader = PDFPlumberLoader(target_path)
            pages = loader.load()
            
        elif file_type == "xlsx" or file_type == 'xls': 
            df = pd.read_excel(target_path)
            df = df.dropna(subset=["answer"])
            loader = DataFrameLoader(df, page_content_column="answer") # ì—¬ê¸° ì£¼ê¸°ì ìœ¼ë¡œ ë°”ê¿”ì¤˜ì•¼ í•¨
            pages = loader.load()
            
        elif file_type == "csv":
            df = pd.read_csv(target_path, encoding="EUC-KR")  # ì¸ì½”ë”© ëª…í™•íˆ ì§€ì •
            df = df.dropna(subset=["ê¸´ê¸‰êµ¬ì¡°ë¶„ë¥˜ëª…"]) 
            loader = DataFrameLoader(df, page_content_column="ê¸´ê¸‰êµ¬ì¡°ë¶„ë¥˜ëª…")
            pages = loader.load()
            
        elif file_type == 'hwp' or file_type == 'hwpx': #hwp5txt
            loader = HWPLoader(target_path)
            pages = loader.load()
            
        elif file_type == 'txt':
            loader = TextLoader(target_path, encoding='utf-8')  # ì¸ì½”ë”©ì„ utf-8ë¡œ ì§€ì •
            pages = loader.load()
            
        elif file_type == 'json':
            loader = JSONLoader(
                file_path = target_path,
                text_content=False
            )
        #  format_doc(pages)
        print(pages)
            
        if not pages:
            raise ValueError("íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # í…ìŠ¤íŠ¸ ë¶„í•  ë° ì²­í‚¹
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
        text_chunks = text_splitter.split_documents(pages)
        
        # 3. ìµœì†Œ í¬ê¸° í•„í„°ë§
        filter_text_chunks = [
            doc for doc in text_chunks if len(doc.page_content.strip()) >= int(min_chunk_size)
        ]
        
        # Embeddingê³¼ Vector Store ì„¤ì •
        embeddings = OllamaEmbeddings(model=model_name)  # ì‚¬ìš©í•˜ë ¤ëŠ” Embedding ëª¨ë¸
        
        ## Retriever ì„¤ì •(chroma, FAISS, bm25)
        ## Chroma retriever ì‚¬ìš©í•´ì„œ í•™ìŠµ
        # vector_store = Chroma.from_documents(filter_text_chunks, embeddings) 
        
        # for i, chunk in tqdm(enumerate(filter_text_chunks), total=len(filter_text_chunks), desc="Vectorizing documents"):
        #     # ê° í…ìŠ¤íŠ¸ ë©ì–´ë¦¬ë¥¼ ë²¡í„°í™”í•˜ì—¬ ì €ì¥
        #     vector_store.add_documents([chunk])
        
        # chroma_retriever = vector_store.as_retriever(
        #     search_type="similarity",
        #     search_kwargs={"k": 3}
        #     )
    
        # FAISS_vectorstore ì´ìš©í•´ì„œ í•™ìŠµ
        FAISS_vectorstore = FAISS.from_documents(documents=filter_text_chunks,
                                                embedding=embeddings,
                                                distance_strategy = DistanceStrategy.COSINE,
                                                )
        FAISS_vectorstore.save_local("./db/faiss_index/{session_id}")
        faiss_retriever = FAISS_vectorstore.as_retriever(search_type="mmr", search_kwargs={"k": 3})
        
        bm25_retriever = BM25Retriever.from_documents(filter_text_chunks)
        bm25_retriever.k = 3
        
        
        # ì•™ìƒë¸” retriever(2ê°œ ì´ìƒ)
        ensemble_retriever = EnsembleRetriever(
            retrievers=[faiss_retriever, bm25_retriever],
            weights=[0.5, 0.5],
        )
        
        query = message
        # FAISSì™€ BM25ì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤
        faiss_docs = faiss_retriever.get_relevant_documents(query)
        bm25_docs = bm25_retriever.get_relevant_documents(query)
        ensemble_docs = ensemble_retriever.get_relevant_documents(query)
        
        # FAISSì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œ í‘œì‹œ
        print("### FAISS ê²€ìƒ‰ëœ ë¬¸ì„œ ###")
        for rank, doc in enumerate(faiss_docs, start=0):
            print(f"Rank: {rank}")
            print(f"Document Title: {doc.metadata.get('title', 'No Title')}")
            print(f"Document Content: {doc.page_content}\n")

        # BM25ì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œ í‘œì‹œ
        print("### BM25 ê²€ìƒ‰ëœ ë¬¸ì„œ ###")
        for rank, doc in enumerate(bm25_docs, start=0):
            print(f"Rank: {rank}")
            print(f"Document Title: {doc.metadata.get('title', 'No Title')}")
            print(f"Document Content: {doc.page_content}\n")
            
        # BM25ì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œ í‘œì‹œ
        print("### ì•™ìƒë¸” ê²€ìƒ‰ëœ ë¬¸ì„œ ###")
        for rank, doc in enumerate(ensemble_docs, start=0):
            print(f"Rank: {rank}")
            print(f"Document Title: {doc.metadata.get('title', 'No Title')}")
            print(f"Document Content: {doc.page_content}\n")
        
        
        # # âœ… Rerank ëª¨ë¸ ë¡œë“œ
        # reranker = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")
        
        # # âœ… 2. RAGì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        # query = "ì‚¬ìš©ìì˜ ì§ˆë¬¸"  # ğŸ”µ ì‹¤ì œ ì‚¬ìš©ì ì…ë ¥ê°’ìœ¼ë¡œ ëŒ€ì²´
        # retrieved_docs = ensemble_retriever.get_relevant_documents(query)

        # # âœ… 3. Rerank ì ìš© (ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ë°˜ ì •ë ¬)
        # document_texts = [doc.page_content for doc in retrieved_docs]  # ğŸ”µ ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        # scores = reranker.predict([(query, doc) for doc in document_texts])  # ğŸ”µ ë¬¸ì¥-ì§ˆë¬¸ ìœ ì‚¬ë„ í‰ê°€
        # reranked_docs = [doc for _, doc in sorted(zip(scores, retrieved_docs), key=lambda x: x[0], reverse=True)]

        # # âœ… 4. ìµœì¢… ìƒìœ„ ë¬¸ì„œ ì„ íƒ (Top 5)
        # final_docs = reranked_docs[:5]
        
        # í…œí”Œë¦¿ ì„¤ì •
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", """ë‹¹ì‹ ì€ ê°•ì§„ì—ì„œ ì œê³µí•˜ëŠ” ì±—ë´‡ ì•ˆë‚´ì›ìœ¼ë¡œ, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ê³µì†í•˜ê²Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. 
                íŒŒì¼ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ë°ì´í„°ë¥¼ ì •í™•íˆ ì½ê³  í•„ìš”í•œ ì •ë³´ë¥¼ ê°„ëµí•˜ê²Œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

                ### ğŸ”¹ **ğŸ“Œ í•µì‹¬ ì›ì¹™**
                1. **ë‹µë³€ ì‹œ ìœ ì˜ ì‚¬í•­**: 
                    - ì…ë ¥ë°›ì€ ë°ì´í„° ë‚´ì— ìˆëŠ” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì´ ì§ˆë¬¸í•˜ëŠ” ì •ë³´ì˜ ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
                    - ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•  ì‹œ í•´ë‹¹ ì •ë³´ë¥¼ ë‹¤ì‹œ ë¬¼ì–´ë´ì•¼ í•©ë‹ˆë‹¤.
            
                2. **ì–¸ì–´ ì •ì±…**:
                    - ê¸°ë³¸ì ìœ¼ë¡œ **ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´**ë¡œ ì‘ì„±ë©ë‹ˆë‹¤.
                    - ì§ˆë¬¸ì— **í•œêµ­ì–´ê°€ í¬í•¨ëœ ê²½ìš°** ìµœëŒ€í•œ í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
                    - ì§ˆë¬¸ì´ **í•œêµ­ì–´ê°€ ì•„ë‹Œ ê²½ìš°**, í•´ë‹¹ ì–¸ì–´ë¡œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                
                3. **ë‹µë³€ ìŠ¤íƒ€ì¼**:
                    - ë‹µë³€ì˜ ëì—ëŠ” ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆë„ë¡ **ì¹œì ˆí•œ ì•ˆë‚´ ë¬¸êµ¬**ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
                    - **ì¤‘ë³µì„ í”¼í•˜ê³ , í•µì‹¬ ì •ë³´ë§Œ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ì œê³µ**í•©ë‹ˆë‹¤.
                """),
                ("human", "{question}")
            ]
        )
        
        # Chain ìƒì„±
        chain = bm25_retriever | prompt | llm | StrOutputParser() 
        
        response = chain.invoke(message) 
        print(type(response), response)
        
        # âœ… JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        answer_text = {"answer": response.content if hasattr(response, 'content') else str(response)}
        
        return answer_text  # ìƒì„±ëœ QA ì²´ì¸ ë°˜í™˜
    
    except Exception as e:
        print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        raise

# ========================================================================= # 
# AGENTIC RAG ì„¤ì •í•˜ëŠ” ì½”ë“œ(ex.ê°•ì§„)

@router.get("/response_agent",  tags=["CHAT BOT API SERVER"])
def response_agent(session_id: int, prompt : str):
    """ì£¼ì œë³„ agent í…œí”Œë¦¿ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜"""
    
    ### PDF ë¬¸ì„œ ê²€ìƒ‰ ë„êµ¬ (Retriever) ###
    # ì—¬ê¸°ì„œ ì§ˆë¬¸ì— ë§ëŠ” ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ë©°, DBê°€ ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
    loader = TextLoader(prompt)

    # í…ìŠ¤íŠ¸ ë¶„í• ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë¶„í• í•©ë‹ˆë‹¤.
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)

    # ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ë¶„í• í•©ë‹ˆë‹¤.
    split_docs = loader.load_and_split(text_splitter)

    # VectorStoreë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    vector = FAISS.from_documents(split_docs, OllamaEmbeddings())

    # Retrieverë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    retriever = vector.as_retriever()
    
    
    # ê²€ìƒ‰ê¸° ë° tool ë‹¤ì–‘í™”ì…ë‹ˆë‹¤. ì‹¤ì „ì—ì„œëŠ” ì§‘ ë‚´ìš©, ì§‘ ê°€ê²©, ê°•ì§„ ë‚´ ì •ë³´ ë“± íŠ¹ì • ë¶„ì•¼ì—ì„œ ë‹¤ì–‘í™”í• ê±°ì˜ˆìš”.
    retriever_tool = create_retriever_tool(
    retriever,
    "db_search",
    "DBì—ì„œ ì°¾ì€ ì •ë³´ë“¤ì…ë‹ˆë‹¤. DB ë‚´ ì •ë³´ë¥¼ ì°¾ê³  ì‹¶ì„ ë•Œ í•´ë‹¹ ê²€ìƒ‰ê¸°ë¥¼ ì£¼ë¡œ ì´ìš©í•˜ì„¸ìš”!",
    )
    
    retriever_tool2 = create_retriever_tool(
    retriever,
    "web_search",
    "ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì°¾ì€ ì •ë³´ë“¤ì…ë‹ˆë‹¤. ì›¹ì‚¬ì´íŠ¸ ë‚´ ì •ë³´ë¥¼ ì°¾ê³  ì‹¶ì„ ë•Œ í•´ë‹¹ ê²€ìƒ‰ê¸°ë¥¼ ì£¼ë¡œ ì´ìš©í•˜ì„¸ìš”!",
    )
    
    retriever_tool3 = create_retriever_tool(
    retriever,
    "RAG_search",
    "RAG ê²€ìƒ‰ì„ í†µí•´ ì°¾ì€ ì •ë³´ë“¤ì…ë‹ˆë‹¤. RAG ë°ì´í„° ë‚´ ì •ë³´ë¥¼ ì°¾ê³  ì‹¶ì„ ë•Œ í•´ë‹¹ ê²€ìƒ‰ê¸°ë¥¼ ì£¼ë¡œ ì´ìš©í•˜ì„¸ìš”!",
    )

    # í•´ë‹¹ agent ë’¤ ìª½ì— json_promptì¼ ì‹œ react -> json_chatìœ¼ë¡œ ë³€ê²½
    agent = create_react_agent(llm, retriever_tool)
    agent2 = create_react_agent(llm, retriever_tool2)
    agent3 = create_react_agent(llm, retriever_tool3)
    
    # agent_executorì˜ ê²½ìš° tool ë° agentë¥¼ Listí™” í•˜ì—¬ ìƒí™©ì— ë§ëŠ” retrieverë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    agent_executor = AgentExecutor(
        agent=agent,  # agent ì„ íƒ
        tools=retriever_tool, # ê²€ìƒ‰ê¸° íˆ´ ì„ íƒ
        verbose=True, # ì–¸ì–´ ì—¬ë¶€
        handle_parsing_errors=True, # parser ì—ëŸ¬ì‹œ ì„ì˜ ë³µêµ¬
        return_intermediate_steps=True, # ì¤‘ê°„ê³¼ì •
    )
    
    # ì±„íŒ… ë©”ì‹œì§€ ê¸°ë¡ì´ ì¶”ê°€ëœ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    agent_with_chat_history = RunnableWithMessageHistory(
        agent_executor,
        # ëŒ€ë¶€ë¶„ì˜ ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì„¸ì…˜ IDê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— ì´ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ë‚´ ChatMessageHistoryë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì‹¤ì œë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤
        lambda session_id: session_id,
        # í”„ë¡¬í”„íŠ¸ì˜ ì§ˆë¬¸ì´ ì…ë ¥ë˜ëŠ” key: "input"
        input_messages_key="input",
        # í”„ë¡¬í”„íŠ¸ì˜ ë©”ì‹œì§€ê°€ ì…ë ¥ë˜ëŠ” key: "chat_history"
        history_messages_key="chat_history",
        )
    
    # ì§ˆì˜ì— ëŒ€í•œ ë‹µë³€ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
    response = agent_with_chat_history.invoke(
        {
            "input": "ê°•ì§„ ë¹ˆì§‘ì— ëŒ€í•œ ì§ˆë¬¸ ë‚´ìš©ì„ DB ë‚´ ì •ë³´ì—ì„œ ì•Œë ¤ì¤˜"
        },
        # ì„¸ì…˜ IDë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
        config={"configurable": {"session_id": session_id}},
    )
    print(f"ë‹µë³€: {response['output']}")

# í•´ë‹¹ ë¶€ë¶„ì€ agent ì‹¤í—˜ìš©ìœ¼ë¡œ, ì‹¤ì „ì—ì„  ì•ˆ ì“°ëŠ” ì½”ë“œì˜ˆìš”.
# ========================================================================= # 
# âœ… ë°ì´í„° ì‹œê°í™” ê¸°ëŠ¥ (ê·¸ë˜í”„ ìƒì„±)
@router.get("/visualize",  tags=["CHAT BOT API SERVER"])
def visualize(session_id: int, prompt : str):
    # ì˜ˆì œ ë°ì´í„°
    data = [
        {"category": "A", "value": 10},
        {"category": "B", "value": 20},
        {"category": "C", "value": 15},
        {"category": "D", "value": 25},
        {"category": "E", "value": 18},
    ]
    df = pd.DataFrame(data)

    # ë°” ì°¨íŠ¸ ìƒì„±
    plt.figure(figsize=(6, 4))
    df.plot(kind="bar", x="category", y="value", legend=False, color="skyblue")
    plt.xlabel("Category")
    plt.ylabel("Value")
    plt.title("ë°ì´í„° ì‹œê°í™” ê²°ê³¼")
    plt.xticks(rotation=0)

    # ê·¸ë˜í”„ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (Base64)
    img_io = io.BytesIO()
    plt.savefig(img_io, format="png", bbox_inches="tight")
    img_io.seek(0)
    img_base64 = base64.b64encode(img_io.read()).decode("utf-8")

    return {"image": f"data:image/png;base64,{img_base64}"}